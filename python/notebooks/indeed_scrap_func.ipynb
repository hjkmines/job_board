{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from datetime import datetime, date\n",
    "import undetected_chromedriver as uc\n",
    "from urllib.parse import urlencode, urljoin \n",
    "import json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import undetected_chromedriver as uc\n",
    "from urllib.parse import urlencode, urljoin\n",
    "import json\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "import requests\n",
    "from time import sleep\n",
    "import re\n",
    "\n",
    "\n",
    "def scrape_indeed(query=\"junior software developer\", pages=1, wait=5):\n",
    "    home = 'https://www.indeed.com'\n",
    "    base = \"https://www.indeed.com/jobs?\"\n",
    "    params = {}\n",
    "    params['q'] = query\n",
    "    params['sort'] = 'date'\n",
    "\n",
    "    titles = []\n",
    "    companies = []\n",
    "    links = []\n",
    "    remote = []\n",
    "    cities = []\n",
    "    states = []\n",
    "    countries = []\n",
    "    zips = []\n",
    "    points = []\n",
    "    dates = []\n",
    "    raw_dates = []\n",
    "    mins = []\n",
    "    maxes = []\n",
    "    types = []\n",
    "    descriptions = []\n",
    "\n",
    "    def get_location(location: str):\n",
    "        res = requests.get(f'https://geocode.maps.co/search?q={location}')\n",
    "        data = res.json()[0]\n",
    "        coordinates = [float(data.get('lon')), float(data.get('lat'))]\n",
    "        sleep(0.5)\n",
    "        if coordinates:\n",
    "            return {'type': 'MultiPoint', 'coordinates': [coordinates]}\n",
    "        return None\n",
    "\n",
    "    # web driver setup\n",
    "    driver = uc.Chrome()\n",
    "\n",
    "    for page in range(0, pages):\n",
    "        params['start'] = str(page*10)\n",
    "        url = base + urlencode(params)\n",
    "        driver.get(url)\n",
    "        sleep(wait)\n",
    "\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        jobs_list = soup.find('div', attrs={'id': 'mosaic-provider-jobcards'})\n",
    "\n",
    "        # extracting data from each job card\n",
    "        titles += [title.text for title in jobs_list.find_all(\n",
    "            'h2', class_='jobTitle')]\n",
    "\n",
    "        companies += [company.text for company in jobs_list.find_all(\n",
    "            'span', class_='companyName')]\n",
    "\n",
    "        page_links = [urljoin(home, link['href'])\n",
    "                      for link in jobs_list.find_all('a', class_='jcs-JobTitle')]\n",
    "        links += page_links\n",
    "\n",
    "        for link in page_links:\n",
    "            try:\n",
    "                driver.get(link)\n",
    "                sleep(wait)\n",
    "                html = driver.page_source\n",
    "                cup = BeautifulSoup(html, 'html.parser')\n",
    "            except:\n",
    "                cup = None\n",
    "\n",
    "            try:\n",
    "                description = cup.find('div', id='jobDescriptionText')\n",
    "                descriptions.append(description.text.lstrip())\n",
    "            except:\n",
    "                descriptions.append('')\n",
    "\n",
    "            try:\n",
    "                job_script = cup.find(\n",
    "                    'script', attrs={'type': \"application/ld+json\"})\n",
    "                job_json = json.loads(str(job_script.contents[0]))\n",
    "                try:\n",
    "                    raw_dates.append(job_json['datePosted'])\n",
    "                    date_posted = datetime.strptime(job_json['datePosted'], '%a, %d %b %Y %H:%M:%S %Z')\n",
    "                    print(date_posted)\n",
    "                    dates.append(date_posted)\n",
    "\n",
    "\n",
    "                except:\n",
    "                    dates.append(job_json['datePosted'])\n",
    "\n",
    "            except:\n",
    "                dates.append(None)\n",
    "\n",
    "            try:\n",
    "                address = job_json['jobLocation']['address']\n",
    "                cities.append(address.get('addressLocality'))\n",
    "                if re.search('remote|anywhere|everywhere', address.get('addressLocality')):\n",
    "                    remote.append(True)\n",
    "                else:\n",
    "                    remote.append(False)\n",
    "                states.append(address.get('addressRegion1'))\n",
    "                zips.append(address.get('postalCode'))\n",
    "                countries.append(address.get('addressCountry'))\n",
    "                points.append(get_location(\n",
    "                    f\"{address.get('addressLocality')}, {address.get('addressRegion1')}, {address.get('addressCountry')}\"))\n",
    "\n",
    "            except:\n",
    "                cities.append(None)\n",
    "                states.append(None)\n",
    "                zips.append(None)\n",
    "                countries.append(None)\n",
    "                points.append(None)\n",
    "\n",
    "            try:\n",
    "                mins.append(int(job_json['baseSalary']['value']['minValue']))\n",
    "                maxes.append(int(job_json['baseSalary']['value']['maxValue']))\n",
    "                types.append(job_json['baseSalary']['value']['unitText'])\n",
    "            except:\n",
    "                mins.append(None)\n",
    "                maxes.append(None)\n",
    "                types.append(None)\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['title'] = titles\n",
    "    df['company'] = companies\n",
    "    df['link'] = links\n",
    "    df['description'] = descriptions\n",
    "    df['date'] = dates\n",
    "    df['raw_date'] = raw_dates\n",
    "    df['min_salary'] = mins\n",
    "    df['max_salary'] = maxes\n",
    "    df['salary_type'] = types\n",
    "    df['city'] = cities\n",
    "    df['state'] = states\n",
    "    df['country'] = countries\n",
    "    df['points'] = points\n",
    "    df['remote'] = remote\n",
    "    df['source'] = 'indeed'\n",
    "    print(df['date'].dtype)\n",
    "    return df\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "df=scrape_indeed(pages=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date']).dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date']=df['date'].dt.to_pydatetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2023-05-25 02:32:27\n",
       "1    2023-05-25 01:08:05\n",
       "2    2023-05-24 21:52:06\n",
       "3    2023-05-24 21:36:40\n",
       "4    2023-05-24 22:05:14\n",
       "5    2023-05-24 23:54:15\n",
       "6    2023-05-24 22:30:08\n",
       "7    2023-05-24 21:23:59\n",
       "8    2023-05-24 15:30:14\n",
       "9    2023-05-24 17:24:03\n",
       "10   2023-05-24 16:09:41\n",
       "11   2023-05-24 18:29:03\n",
       "12   2023-05-24 16:33:58\n",
       "13   2023-05-24 12:58:24\n",
       "14   2023-05-24 18:15:54\n",
       "Name: date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'indeed_{date.today()}.csv')\n",
    "df.to_json(f'indeed_{date.today()}.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
